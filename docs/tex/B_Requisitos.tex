\apendice{Especificación de Requisitos}

\section{Introducción}

Una muestra de cómo podría ser una tabla de casos de uso:


\section{Objetivos generales}
A lo largo del desarrollo del estudio, se han ido anotando todas las tareas solicitadas para cada sprint en el \href{https://github.com/hds1001/Estudio-y-configuracion-de-un-sistema-ELK}{repositorio} GitHub del proyecto, por lo que en este apartado se hará un desglose de cada tarea involucrada.

\section{Catálogo de requisitos}
En este apartado se muestra cada \textit{issue} presente en el desarrollo del proyecto junto con datos como la fecha, el autor o el sprint al que pertenecen.

\begin{itemize}
    \item \textbf{Investigación e instalación de Kibana}
    \begin{itemize}
        \item \textbf{Número:} \#1
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 24 de febrero
        \item \textbf{Sprint:} Sprint Inicial
    \end{itemize}
    
    \item \textbf{Investigación e instalación de ElasticSearch}
    \begin{itemize}
        \item \textbf{Número:} \#2
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 24 de febrero
        \item \textbf{Sprint:} Sprint Inicial
    \end{itemize}
    
    \item \textbf{Investigación e instalación de Logstash}
    \begin{itemize}
        \item \textbf{Número:} \#3
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 24 de febrero
        \item \textbf{Sprint:} Sprint Inicial
    \end{itemize}
    
    \item \textbf{Configuración del repositorio GitHub}
    \begin{itemize}
        \item \textbf{Número:} \#4
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 17 de marzo
        \item \textbf{Sprint:} Sprint Inicial
    \end{itemize}
    
    \item \textbf{Inicio documentación de la memoria}
    \begin{itemize}
        \item \textbf{Número:} \#5
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 7 de marzo
        \item \textbf{Sprint:} Sprint Inicial
    \end{itemize}
    
    \item \textbf{Comenzar con la documentación de la memoria en LaTeX}
    \begin{itemize}
        \item \textbf{Número:} \#6
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 8 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Investigar sobre la funcionalidad de Machine Learning en Elastic}
    \begin{itemize}
        \item \textbf{Número:} \#7
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 13 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Investigar funcionamiento filtrado Logstash}
    \begin{itemize}
        \item \textbf{Número:} \#8
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 11 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Investigar desarrollo con plugins en ElasticSearch}
    \begin{itemize}
        \item \textbf{Número:} \#9
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 31 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Investigar posible integración con Python para el tratamiento de datos}
    \begin{itemize}
        \item \textbf{Número:} \#10
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 13 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Investigar desarrollo con Docker y como integrarlo}
    \begin{itemize}
        \item \textbf{Número:} \#11
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 13 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Investigar funcionamiento MapReduce en Logstash}
    \begin{itemize}
        \item \textbf{Número:} \#12
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 3 de abril
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Investigar funcionamiento MapReduce en ElasticSearch}
    \begin{itemize}
        \item \textbf{Número:} \#13
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 28 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Investigar funcionamiento MapReduce en Kibana}
    \begin{itemize}
        \item \textbf{Número:} \#14
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 28 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Probar filtrado en Logstash: sumas, agrupamientos, discretizar columna numérica}
    \begin{itemize}
        \item \textbf{Número:} \#15
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 1 de abril
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Continuar con documentación en Overleaf}
    \begin{itemize}
        \item \textbf{Número:} \#16
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 4 días atrás
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Familiarización con librería SKLearn en cuanto a clasificación, regresión, clustering y PCA}
    \begin{itemize}
        \item \textbf{Número:} \#17
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 29 de marzo
        \item \textbf{Sprint:} Sprint 2
    \end{itemize}
    
    \item \textbf{Cargar datos Iris en Kibana}
    \begin{itemize}
        \item \textbf{Número:} \#18
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 15 de abril
        \item \textbf{Sprint:} Sprint 3
    \end{itemize}
    
    \item \textbf{Explorar más posibilidades de agrupamiento en Logstash con máximos, medias, etc.}
    \begin{itemize}
        \item \textbf{Número:} \#19
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 2 de mayo
        \item \textbf{Sprint:} Sprint 3
    \end{itemize}
    
    \item \textbf{Probar Data Streams: los que se puede y no (funcionamiento, campos, etc.)}
    \begin{itemize}
        \item \textbf{Número:} \#20
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 17 de abril
        \item \textbf{Sprint:} Sprint 3
    \end{itemize}
    
    \item \textbf{Comparar MapReduce en Kibana con Logstash}
    \begin{itemize}
        \item \textbf{Número:} \#21
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 18 de abril
        \item \textbf{Sprint:} Sprint 3
    \end{itemize}

        \item \textbf{Probar Data Streams: los que se puede y no (funcionamiento, campos, etc.)}
    \begin{itemize}
        \item \textbf{Número:} \#22
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 29 de abril
        \item \textbf{Sprint:} Sprint 3
    \end{itemize}

        \item \textbf{Probar funcionamiento Data Streams}
    \begin{itemize}
        \item \textbf{Número:} \#23
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 2 de mayo
        \item \textbf{Sprint:} Sprint 4
    \end{itemize}
    
    \item \textbf{Investigar funcionamiento WebSocket en ELK}
    \begin{itemize}
        \item \textbf{Número:} \#24
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 2 de mayo
        \item \textbf{Sprint:} Sprint 4
    \end{itemize}

        \item \textbf{Conectar WebSocket con Logstash}
    \begin{itemize}
        \item \textbf{Número:} \#25
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 3 de mayo
        \item \textbf{Sprint:} Sprint 4
    \end{itemize}
    
    \item \textbf{Estudiar posibilidad hacer MapReduce del data stream en Logstash}
    \begin{itemize}
        \item \textbf{Número:} \#26
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 5 de mayo
        \item \textbf{Sprint:} Sprint 5
    \end{itemize}
    
    \item \textbf{Investigar funcionamiento MapReduce en Kibana}
    \begin{itemize}
        \item \textbf{Número:} \#27
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 5 de mayo
        \item \textbf{Sprint:} Sprint 5
    \end{itemize}
    
    \item \textbf{Investigar sobre el Edge Computing y como funciona}
    \begin{itemize}
        \item \textbf{Número:} \#28
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 5 de mayo
        \item \textbf{Sprint:} Sprint 5
    \end{itemize}
    
    \item \textbf{Estudiar caso importar directamente el fichero en Elastic}
    \begin{itemize}
        \item \textbf{Número:} \#29
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 9 de mayo
        \item \textbf{Sprint:} Sprint 6
    \end{itemize}
    
    \item \textbf{Estudiar caso importar el fichero desde Logstash}
    \begin{itemize}
        \item \textbf{Número:} \#30
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 12 de mayo
        \item \textbf{Sprint:} Sprint 6
    \end{itemize}
    
    \item \textbf{Estudiar caso importar un DataSet (Iris)}
    \begin{itemize}
        \item \textbf{Número:} \#31
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} Último mes
        \item \textbf{Sprint:} Sprint 6
    \end{itemize}
    
    \item \textbf{Estudiar caso importar a través de WebSocket a Elastic}
    \begin{itemize}
        \item \textbf{Número:} \#32
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} Último mes
        \item \textbf{Sprint:} Sprint 6
    \end{itemize}
    
    \item \textbf{Estudiar caso importar a través de un WebSocket con Logstash}
    \begin{itemize}
        \item \textbf{Número:} \#33
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} Último mes
        \item \textbf{Sprint:} Sprint 6
    \end{itemize}
    
    \item \textbf{Investigar sobre el caso de Edge Computing y cómo funciona}
    \begin{itemize}
        \item \textbf{Número:} \#34
        \item \textbf{Autor:} Hugo de la Cámara
        \item \textbf{Fecha:} 4 días atrás
        \item \textbf{Sprint:} Sprint 7
    \end{itemize}

\end{itemize}


\section{Especificación de requisitos}

Para adaptar este apartado al estudio, en esta sección se va a exponer cada escenario realizado como si fuera un caso de uso, adaptando la tabla de manera que se adecue a la información que se quiere mostrar
\begin{table}[p]
	\centering
	\begin{tabularx}{\linewidth}{ p{0.21\columnwidth} p{0.71\columnwidth} }
		\toprule
		\textbf{CU-1}    & \textbf{Escenario 1: ingesta de fichero desde Elastic}\\
		\toprule
		\textbf{Versión}              & 1.0    \\
		\textbf{Autor}                & Hugo de la Cámara Saiz \\
		\textbf{Descripción}          & En este escenario se pretende ingestar un fichero de tipo CSV directamente desde Elastic sin intermediarios. \\
		\textbf{Precondición}         & Tener el fichero titanic.csv en el sistema local \\
		\textbf{Acciones}             &
		\begin{enumerate}
			\def\labelenumi{\arabic{enumi}.}
			\tightlist
			\item Importar el archivo desde el menú de Elastic
                \item Comprobar en el Index Management que el índice se ha generado correctamente
			\item Comprobar en el Discoverer que el contenido del archivo ha sido importado correctamente.
                \item Mostrar en un dashboard visualizaciones de los datos.
		\end{enumerate}\\
		\textbf{Importancia}          & Alta \\
		\bottomrule
	\end{tabularx}
	\caption{CU-1 Escenario 1: ingesta de fichero desde Elastic}
\end{table}

\begin{table}[p]
	\centering
	\begin{tabularx}{\linewidth}{ p{0.21\columnwidth} p{0.71\columnwidth} }
		\toprule
		\textbf{CU-1}    & \textbf{Escenario 2: ingesta de fichero desde Logstash}\\
		\toprule
		\textbf{Versión}              & 1.0    \\
		\textbf{Autor}                & Hugo de la Cámara Saiz \\
		\textbf{Descripción}          & En este escenario se pretende ingestar un fichero de tipo log desde Logstash aplicándole una serie de transformaciones y mandarlo a Elastic posteriormente. \\
		\textbf{Precondición}         & Tener el fichero .log en el sistema local \\
		\textbf{Acciones}             &
		\begin{enumerate}
			\def\labelenumi{\arabic{enumi}.}
			\tightlist
			\item Crear un archivo .conf para Logstash en el que se le indique la ruta al input de los datos.
                \item Modificar en la sección filter las diferentes transformaciones que se quieren aplicar.
                \item Indicar en la sección output que se quiere mandar a ElasticSearch los datos procesados.
                \item Ejecutar Logstash con el archivo de configuración creado.
                \item Comprobar en el Index Management que el índice se ha generado correctamente
			\item Comprobar en el Discoverer que el contenido del archivo ha sido importado correctamente.
                \item Mostrar en un dashboard visualizaciones de los datos.
		\end{enumerate}\\
		\textbf{Importancia}          & Alta \\
		\bottomrule
	\end{tabularx}
	\caption{CU-1 Escenario 2: ingesta de fichero desde Logstash}
\end{table}

\begin{table}[p]
	\centering
	\begin{tabularx}{\linewidth}{ p{0.21\columnwidth} p{0.71\columnwidth} }
		\toprule
		\textbf{CU-1}    & \textbf{Escenario 3: ingesta desde WebSocket a Elastic}\\
		\toprule
		\textbf{Versión}              & 1.0    \\
		\textbf{Autor}                & Hugo de la Cámara Saiz \\
		\textbf{Descripción}          & En este escenario se pretende ingestar un data stream desde el WebSocket de Finnhub directamente a Elastic, sin intermediarios. \\
		\textbf{Precondición}         & Poseer una key de suscripción a la API de Finnhub \\
		\textbf{Acciones}             &
		\begin{enumerate}
			\def\labelenumi{\arabic{enumi}.}
			\tightlist
			\item Crear un script para estructurar la suscripción y los campos que se quieren mandar.
                \item Establecer como ruta de destino ElasticSearch
                \item Ejecutar el script de manera que se muestren en la terminal los datos que se están mandando en vivo.
                \item Comprobar en el Index Management que el índice se ha generado correctamente
			\item Comprobar en el Discoverer que el contenido del data stream ha sido importado correctamente.
                \item Mostrar en un dashboard visualizaciones de los datos.
		\end{enumerate}\\
		\textbf{Importancia}          & Alta \\
		\bottomrule
	\end{tabularx}
	\caption{CU-1 Escenario 3: ingesta desde WebSocket a Elastic}
\end{table}

\begin{table}[p]
	\centering
	\begin{tabularx}{\linewidth}{ p{0.21\columnwidth} p{0.71\columnwidth} }
		\toprule
		\textbf{CU-1}    & \textbf{Escenario 4: ingesta de WebSocket desde Logstash}\\
		\toprule
		\textbf{Versión}              & 1.0    \\
		\textbf{Autor}                & Hugo de la Cámara Saiz \\
		\textbf{Descripción}          & En este escenario se pretende ingestar un data stream del WebSocket de Finnhub desde Logstash, procesar los datos y que se manden a Elastic. \\
		\textbf{Precondición}         & Poseer una key de suscripción a la API de Finnhub \\
		\textbf{Acciones}             &
		\begin{enumerate}
			\def\labelenumi{\arabic{enumi}.}
			\tightlist
			\item Crear un script para estructurar la suscripción y los campos que se quieren mandar.
                \item Establecer como ruta de destino Logstash.
                \item Ejecutar el script de manera que se muestren en la terminal los datos que se están mandando en vivo.
                \item Crear un archivo .conf para Logstash en el que se le indique que el input de los datos va a ser el WebSocket de Finnhub.
                \item Modificar en la sección filter las diferentes transformaciones que se quieren aplicar.
                \item Indicar en la sección output que se quiere mandar a ElasticSearch los datos procesados.
                \item Ejecutar Logstash con el archivo de configuración creado.
                \item Comprobar en el Index Management que el índice se ha generado correctamente
			\item Comprobar en el Discoverer que el contenido del data stream ha sido importado correctamente.
                \item Mostrar en un dashboard visualizaciones de los datos
		\end{enumerate}\\
		\textbf{Importancia}          & Alta \\
		\bottomrule
	\end{tabularx}
	\caption{CU-1 Escenario 4: ingesta de WebSocket desde Logstash}
\end{table}

\begin{table}[p]
	\centering
	\begin{tabularx}{\linewidth}{ p{0.21\columnwidth} p{0.71\columnwidth} }
		\toprule
		\textbf{CU-1}    & \textbf{Escenario 5: ingesta de data stream desde Logstash aplicando MapReduce}\\
		\toprule
		\textbf{Versión}              & 1.0    \\
		\textbf{Autor}                & Hugo de la Cámara Saiz \\
		\textbf{Descripción}          & En este escenario se pretende ingestar los datos de un data stream procesados aplicando MapReduce por Logstash hasta Elastic. \\
		\textbf{Precondición}         & Ninguna  \\
		\textbf{Acciones}             &
		\begin{enumerate}
			\def\labelenumi{\arabic{enumi}.}
			\tightlist
			\item Crear un script para estructurar el data stream y los campos que se quieren mandar.
                \item Establecer como ruta de destino Logstash.
                \item Crear un archivo .conf para Logstash en el que se le indique que el input de los datos va a ser un archivo el cuál irá actualizándose mientras el script este ejecutándose.
                \item Añadir en la sección filter el plugin agreggate con el que se aplicará MapReduce en función de los valores indicados.
                \item Indicar en la sección output que se quiere mandar a ElasticSearch los datos procesados.
                \item Ejecutar Logstash con el archivo de configuración creado.
                \item Comprobar en el Index Management que el índice se ha generado correctamente
			\item Comprobar en el Discoverer que el contenido del data stream ha sido importado correctamente.
                \item Mostrar en un dashboard visualizaciones de los datos.
		\end{enumerate}\\
		\textbf{Importancia}          & Alta \\
		\bottomrule
	\end{tabularx}
	\caption{CU-1 Escenario 5: ingesta de data stream desde Logstash aplicando MapReduce}
\end{table}